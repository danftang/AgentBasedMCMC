\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{amssymb,amsmath,amsthm}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{apacite}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\newtheorem{theorem}{Theorem}
\DeclareMathOperator\supp{supp}

\title{Sampling from the Bayesian poster of an agent-based model given partial observations}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

\author{
  Daniel Tang\\
  Leeds Institute for Data Analytics\thanks{This project has received funding from the European Research Council (ERC) under the European Unionâ€™s Horizon 2020 research and innovation programme (grant agreement No. 757455)}\\
  University of Leeds\\
  Leeds, UK\\
  \texttt{D.Tang@leeds.ac.uk} \\
  %% examples of more authors
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
}


\begin{document}
\maketitle

\begin{abstract}
abstract
\end{abstract}

% keywords can be removed
\keywords{Data assimilation, Bayesian inference, Agent based model, Integer linear programming, predator prey model}

\section{Introduction}
%##########################################


Suppose we have a timestepping ABM where agents have a finite number of possible internal states and a finite number of ways of acting on their world. Given this, we can define an ABM as:
\begin{itemize}
\item A domain of agent actions $\mathcal{A} =\{ a_0 ... a_n \}$

\item A domain of agent states $\mathcal{S} = \{\sigma_0 ... \sigma_m\}$

\item A computer program, $\pi(\psi,\Psi)$,  where $\psi \in \mathcal{S}$ is the agent's state and $\Psi$ is a (sparse) vector whose $i^{th}$ element is the number of agents in state $\sigma_i$ at the start of the timestep. The program can make calls to a random number generator that returns a value $0 \le r < 1$ with uniform probability, so its returned value may be non-deterministic and we write $P(\pi(\psi,\Psi)=a)$ to be the probability that the program will return value $a$, given inputs $\psi$ and $\Psi$. The program returns an action $a \in \mathcal{A}$ which is the action  performed by the agent in this timestep.

\item An agent transition tensor $F_\phi^{\psi a}$ whose elements give the number of agents in state $\phi$ that result from an agent in state $\psi$ performing act $a$ (including the acting agent).
\end{itemize}

As a very simple demonstration, we'll take a spatial predator-prey model where agents are either predator or prey moving about a 2-dimensional grid. In this case, the domain of actions are $\mathbb{A} = \{$move-left, move-right, move-up, move-down, reproduce up, reproduce down, reporduce left, reproduce right, be eaten, die$\}$. So the domain of agent states, $\mathcal{S}$, can be thought of as the class 
\begin{lstlisting}
class Agent {
	Boolean	isaPredator
	Integer	xPosition
	Integer	yPosition
}
\end{lstlisting}

We can assign an ordering of agent states by placing agent \texttt{a} in the (\texttt{a.isaPredator*G$^2$ + a.yPositition*G + a.xPosition})$^{th}$ position, where \texttt{G} is the size of the grid.

\begin{algorithm}
\caption{Timestep of a predator/prey agent}
\label{agentTimestep}
\begin{algorithmic}
\Function{Timestep}{agent, otherAgents}
\If{agent.isaPredator}
  \If{\Call{random}{ } < $\beta_0$ and number of prey on neighbouring gridsquares of otherAgents > 0}
    \State\Return reproduce left, right, up or down based on a call to \Call{Random}{ }
  \EndIf
  \If{\Call{random}{ } < $\gamma_0$}
    \State\Return die
  \EndIf
\Else
  \If{\Call{random}{ } < $\beta_1$}
    \State\Return reproduce left, right, up or down based on a call to \Call{Random}{ }
  \EndIf
  \If{\Call{random}{ } < $\gamma_1$}
    \State\Return die
  \EndIf
  \If{\Call{random}{ } < $\delta$ and number of predators on this or neighbouring gridsquares of otherAgents > 0}
    \State\Return be eaten
  \EndIf
  
\EndIf
\State \Return move left, right, up or down based on a call to \Call{Random}{ }
\EndFunction
\end{algorithmic}
\end{algorithm}

The timestep function for a predator/prey agent is shown in algorithm \ref{agentTimestep} (where we assume the grid has periodic boundary conditions so we don't need to worry about its edges). The transition tensor encodes the results of the various actions. So, for example, the zero$^{th}$ state, $\sigma_0$, corresponds to a prey at position (0,0). If this agent moves right (i.e. performs action $a_1$) then the result is a prey at position (1,0) (i.e. in state $\sigma_1$) so $F^{01}_1 = 1$ etc.

Let a model timestep consist of a matrix $E$ whose elements $e_{\psi a}$ are the number of agents in state $\psi$ that perform act $a$ in this timestep. Similarly, let a model trajectory be a tensor $T^t_{\psi a}$ whose elements are the number of agents in state $\psi$ that perform act $a$ in timestep $t$.

A trajectory must satisfy a number of constraints in order to be a possible trajectory of an ABM. Since the elements of a trajectory are counts, they must all be non-negative integers, we'll call this the \textit{non-negative integer constraint}
\begin{equation}
\forall t,\psi, a: T^t_{\psi a} \in \mathbb{Z}_{\ge 0}
\label{nonNegativeInt}
\end{equation}

A trajectory, $T^t_{\psi a}$, must also be \textit{continuous} which means that each agent that results from the actions of an agent in timestep $t$ must appear in the actions of timestep $t+1$. This can be expressed in terms of the \textit{continuity constraints}:
\begin{equation}
\forall t \in 1 ... n:\forall \phi: \sum_{\psi, a} F_\phi^{\psi a}T^{t-1}_{\psi a} - \sum_a T^t_{\phi a} = 0
\label{continuous}
\end{equation}

If a trajectory satisfies constraints \ref{nonNegativeInt} and \ref{continuous} we say that it is \textit{valid}.

Suppose we have a prior belief, $P_0(\Psi)$, over the state of the ABM at time $t=0$ (in the example of the predator/prey model, let's suppose we know the probability of finding a predator or prey at each gridpoint at $t=0$, but don't know the exact positions of each agent). Given this, the prior probability of a trajectory is
\[
P(T^t_{\psi a}) =
\begin{cases}
P_0(\sum_aT^0_{\psi a}) \prod_{t, \psi, a} P(\pi(\psi,\sum_bT^{t}_{\phi b})=a)^{T^{t}_{\psi a}} & \text{if } T^t_{\psi a} \text{ is valid} \\
0 & \text{otherwise}\\
\end{cases}
\]

Suppose we also have a set of noisy, aggregate observations, $\Omega$, that have a likelihood function $P(\Omega|T^t_{\psi a})$. In our running example, let's suppose we periodically note down when and where we see footprints of predator and prey. Our aim is to generate a number of samples from the posterior distribution
\[
P(T^t_{\psi a}|\Omega) \propto P\left(\Omega \middle| T^{t}_{\psi a}\right)P(T^t_{\psi a})
\]

We assume that observations are independent given the trajectory and that each individual observation in $\Omega$ can be simulated by a computer program $\omega(T^t_{\psi a})$ which may make calls to a random number generator. The probability, $P(\omega(T^t_{\psi a}) = v)$, that the program returns a value $v$ defines the likelihood of observing value $v$ upon making observation $\omega$ on trajectory $T^t_{\psi a}$. i.e. $\omega(T^t_{\psi a})$ is just a simulation of the observation, which is usually quite easy to express as a computer program and to compute. 

In the case of the predator prey model, let's suppose that at the end of every day we go out to a fixed set of inspection sites and check for footprints. Suppose that if predators were present in the grid-square containing an inspection site on that day, there's a 50\% chance we'll see a footprint, and if prey were present, there's a 25\% chance. The observation function for a site is shown in algorithm \ref{observationFunc}

\begin{algorithm}
\caption{Function for observing predator/prey footprints at a site}
\label{observationFunc}
\begin{algorithmic}
\Function{ObserveFootprints}{T} \Comment{T is the ABM trajectory}
\State $t \leftarrow$ time of observation
\State $x \leftarrow$ x-position of observation
\State $y \leftarrow$ y-position of observation
\State $G \leftarrow$ size of grid
\State $\psi \leftarrow G^2 + Gy + x$   \Comment{state of predator in this gridsquare}  
\State $\phi \leftarrow Gy + x$     \Comment{state of prey in this gridsquare}
\State $F_{pred} \leftarrow$ \Call{False}{}  \Comment{did we observe predator footprints?}
\State $F_{prey} \leftarrow$ \Call{False}{}  \Comment{did we observe prey footprints?}

\If{$\sum_a T^t_{\psi a} > 0$ and \Call{Random}{ } < 0.5}
\State $F_{pred} \leftarrow$ \Call{True}{}
\EndIf
\If{$\sum_a T^t_{\phi a} > 0$ and \Call{Random}{ } < 0.25}
\State $F_{prey} \leftarrow$ \Call{True}{}
\EndIf
\State\Return $F_{pred}$, $F_{prey}$
\EndFunction
\end{algorithmic}
\end{algorithm}


Given this
\[
P(\Omega|T^t_{\psi a}) = \prod_{(\omega,v) \in \Omega} P(\omega(T^t_{\psi a})=v)
\]

Also, for notational convenience, and without loss of generality, we express our prior beliefs in terms of a set of observations, $\Omega_0$, at $t=0$, so that $P_0(\sum_a T^0_{\psi a}) \propto \prod_{(\omega,v) \in \Omega_0} P(\omega(T^t_{\psi a})=v)$ (this also allows any priors that aren't at $t=0$). The posterior can now be written as
\begin{equation}
P(T^t_{\psi a}|\Omega) \propto 
\begin{cases}
\prod_{(\omega,v) \in \Omega} P\left(\omega(T^{t}_{\psi a})=v\right) \prod_{t, \psi, a}P(\pi(\psi,\sum_bT^{t}_{\phi b})=a)^{T^{t}_{\psi a}} & \text{if } T^t_{\psi a} \text{ is valid} \\
0 & \text{otherwise}\\
\end{cases}
\label{posterior}
\end{equation}
where $\Omega$ now includes any priors.

In many practical applications, sampling from this posterior is difficult because it has zero probability for the vast majority of trajectories (i.e. most trajectories are invalid, contain an impossible action or are refuted by the observations). This is true of our predator/prey model, for example. Even though we can generate valid trajectories that fit the prior by simply performing a forward execution of the model from an initial state drawn from the prior, if the trajectory has no predator or prey at a time and place that we observed footprints, then the observations refute the trajectory and the probability falls to zero. It doesn't take many observations until the probability of randomly choosing a trajectory that fits the observations becomes very small indeed. So simple techniques such as rejection sampling are not practical.

In this paper we'll use the Metropolis-Hastings algorithm to generate samples. However, this method requires a proposal function which randomly generates the next sample given the current one. However, given the current sample, we still have the problem of finding a trajectory with non-zero probability. For example if we generate a new trajectory by perturbing one or more elements of the last sample at random (a common strategy with Metropolis-Hastings), it's very unlikely that we'll end up with a trajectory that is valid, contains only possible actions and satisfies the observations. So, the proposed next sample would almost certainly be rejected and we'd probably end up stuck on the first sample until we grew old.

\section{Approximating the support of the posterior}
%##########################################


To solve this problem we'd like to constrain our proposal function to the support of the posterior, $\supp(P(T^t_{\psi a}|\Omega))$ (i.e. the set of trajectories that have non-zero probability).

If we let
\[
\pi'(s, \xi, T^t_{\psi a}) = \pi(\xi,\sum_bT^{s}_{\phi b})
\]
Then from equation \ref{posterior}
\begin{equation}
\supp (P( \,.\, |\Omega)) = 
\bigcap_{(\omega,v) \in \Omega}  \supp\left(P\left(\omega(.)=v\right)\right) \cap
\bigcap_{t, \psi, a} \supp\left(P\left( \pi'(t,\psi,.) = a \right)\right) \cap
\left\{T^t_{\psi a} \mid T^t_{\psi a} \text{is valid}\right\}
\label{support}
\end{equation}
i.e. in order for the posterior to be non-zero, all the observation likelihoods must be non-zero, the probability of each agent's action at every timestep must be non-zero and the trajectory must be valid.

The first two terms in equation \ref{support} consists of the supports of computer programs whose inputs are ABM trajectories and whose outputs are given, i.e. the set of trajectories that, when passed to a computer program, would produce a given output.

Calculating the support of a computer program for a given output is, in full generality, NP-complete\footnote{Consider, for example, a program that accepts an assignment of variables to truth values, and returns true if that assignment satisfies a Boolean formula. Deciding whether the support of this program, given that it returns true, is empty or not is equivalent to solving the Boolean satisfiability problem, which is known to be NP-complete\cite{cook1971complexity}} but it is possible to use a technique known as \textit{abstract interpretation}\cite{cousot1977abstract} to efficiently calculate a superset of the support. So, given a computer program $\rho$, we can calculate a set $\mathcal{P}(\rho, v)$ such that
\[
\supp(P(\rho(.)=y)) \subset \mathcal{P}(\rho, v)
\]
Tools to perform abstract interpretation already exist (e.g. PAGAI\cite{henry2012pagai}) and are used widely in applications such as the verification of safety critical systems\cite{blanchet2003static} and in practice $\mathcal{P}(\rho, v)$ is often reasonably tight (i.e. most members of $\mathcal{P}(\rho, v)$ are in $\supp(P(\rho(.)=y))$). For our application we choose to express $\mathcal{P}(\rho, v)$ in terms of a set of linear inequalities on $\rho$'s inputs, this corresponds to the abstract domain of convex polyhedra\cite{cousot1978automatic}\cite{becchi2018efficient}. Calls to the random number generator can be dealt with in the abstract domain by generating a new variable, $r$, that satisfies $0 \le r < 1$ for each call to \texttt{Random()}.

If we replace the supports in equation \ref{support} with their equivalent supersets we end up with a superset of the posterior
\begin{equation}
\supp(P(.|\Omega)) \subset
\bigcap_{(\omega,v) \in \Omega}  \mathcal{P}(\omega, v) \cap
\bigcap_{t, \psi, a} \mathcal{P}(\pi'(t,\psi,.), a) \cap
\left\{T^t_{\psi a} \mid T^t_{\psi a} \text{is valid}\right\}
\label{linearSupport}
\end{equation}
The intersections are now intersections of sets of inequalities which are just the set of trajectories that satisfy all of the inequalities, i.e. the union of the inequalities.

Constraining our proposal function to members of the superset in equation \ref{linearSupport} instead of the true support won't affect the stationary distribution of the Markov Chain. If the proposal function happens to return a trajectory that isn't in $\supp(P(\rho(.)=y))$ then it will just be rejected. This is fine as long as we generate acceptable proposals at a reasonable rate.

It remains for us to deal with the final term in equation \ref{linearSupport}, which requires the trajectories in the support to be valid. The first part of validity, the continuity constraints in \ref{continuous}, are not a problem because they are also linear constraints so can be treated along with the other constraints. The non-negative integer constraints of equation \ref{nonNegativeInt} are left as separate constraints.

Without loss of generality, we express inequalities as equalities by introducing slack variables so that
\[
\sum_i c_i x_i \le y
\]
is equivalent to
\[
\begin{split}
 \sum_i c_i x_i + \lambda & = y \\
\text{subject to}\ \lambda & \ge 0 \\
\end{split}
\]

All the constraints can now be gathered into a standard matrix form
\begin{equation}
\begin{split}
AX &= B \\
\text{subject to}\ x_i &\ge 0\\
x_i &\in \mathbb{Z}
\end{split}
\label{Axy}
\end{equation}
where the vector $x$ contains the elements of the trajectory tensor $T^t_{\psi a}$ and the slack variables $\lambda$.

\section{From convex polyhedron to Markov process}
%#####################################################

Given a set of inequalities that contain the support of the posterior, we next need to define a stochastic proposal function $f:\mathbb{S} \to \mathbb{S}$ on a set of Markov states, $\mathbb{S}$, where each state, $\sigma$, is associated with a trajectory $T(\sigma)$. The proposal function should have the following properties:
\begin{itemize}
\item There should be a set of transitions with non-zero probability between any two Markov states. This ensures proper mixing as time tends to infinity.

\item The probability of being in a state associated with trajectory $T$ should be our target posterior probability $P(T \mid \Omega)$.

\item For any transition from state $s_a \to s_b$ the probability of transitioning from $s_b \to s_a$ should be non-zero. This allows us to attain detailed balance by using the Metropolis Hastings algorithm.

\item The proposal function should be computationally efficient. 
\end{itemize}

\subsection{A proposal function for a Fermionic ABM}
%#############################################

We define a Fermionic ABM to be one where no two agents can share the same state at the same time. i.e. in addition to the validity constraints of equations \ref{nonNegativeInt} and \ref{continuous} the trajectory of a Fermionic ABM also satisfies the \textit{Fermionic constraint}
\begin{equation}
\forall t,\psi: \sum_a T^t_{\psi a} \le 1
\label{fermionic}
\end{equation}
in which case we call it a \textit{Fermionic trajectory} [this can be weakened to $T^t_{\psi a} \le 1$].

\begin{theorem}
All trajectories that satisfy equations \ref{nonNegativeInt}, \ref{continuous} and \ref{fermionic} are at extreme points. Where an extreme point is one that can't be expressed as a linear combination of two other points that satisfy the constraints.
\end{theorem}
\begin{proof}
This can be seen immediately since equations \ref{nonNegativeInt} and \ref{fermionic} describe a unit hupercube, so all integer solutions are on vertices.
\end{proof}

%\begin{theorem}
%For any pair of valid trajectories, $A$ and $B$, there exists a path along edges of the polyhedron from $A$ to $B$ that only traverses through integer solutions.
%\end{theorem}
%\begin{proof}
%[Take the difference A-B and decompose into integer null vectors (loops)]
%\end{proof}

This seemingly abstract fact has a profound practical consequence for the efficiency of our proposal function.
Given a system of $m$ linear constraints on $n$ variables expressed in the form $AX=B$, let a \textit{pivot state} be a partition of the variables into $m$ \textit{basic variables} and $n-m$ \textit{non-basic variables} so we can express the constraints in the form
\begin{equation}
A_bX_b + A_nX_n = B
\label{tableau1}
\end{equation}
where $X_b$ and $X_n$ are the basic and non-basic variables respectively, $A_b$ is the matrix formed from the columns in $A$ that correspond to the basic variables and $A_n$ is the matrix formed from the columns of $A$ that correspond to the non-basic variables. If we now constrain all non-basic variables to zero then we're left with $A_bX_b = B$ but since $A_b$ is an $m \times m$ square matrix then $X_b = A_b^{-1}B$ gives a unique solution, as long as $A_b$ is invertable. If $A_b$ is invertable and $X_b$ has no negative entries then we say that the pivot state is valid. It can be shown that all valid pivot states of equations \ref{Axy} correspond to extreme points\cite{dantzig1955generalized}.

This idea leads to a computationally very efficient way of perturbing trajectories. We begin by representing the constraints and the current trajectory in the form of equation \ref{tableau1}. If we multiply any row of $A_b$ by some constant, $c$, then the truth of equation \ref{tableau1} can be maintained by multiplying the same row of $A_n$ and of $B$ by $c$ as well. Similarly if we add one row of $A_b$ to another row, the equations can be maintained by performing the same row operation on $A_n$ and $B$. If the current trajectory is valid, then $A_b$ must be invertable, so it is possible, by performing a sequence of row additions and multiplications, to transform $A_b$ into a form such that each row and column is zero on all elements except one, which is 1. We'll call this the standard form. Once in this form, the solution $X_b$ can be read off directly from $B$ if we assume $X_n = 0$.

Given a valid solution in standard form, a perturbed valid solution can be generated by choosing a column, $C$, of $A_n$, with at least one positive-valued row, and choosing from among those rows the one, $C_i$, that minimises $B_i/C_i$. We then make the variable corresponding to column $C$ a basic variable and make the basic variable corresponding to row $i$ of $A_b$ non-basic by swapping column $C$ with the column on row $i$ of $A_b$ that has value 1. $A_b$ is now not in standard form as column $C$ will, in general, have more than one non-zero value so we perform row additions and multiplications to return it to standard form. This perturbation is known as a \textit{pivot} operation and is the same method as employed in the Simplex algorithm\cite{dantzig1955generalized}\cite{vanderbei2015linear}. This is exactly what we need for our proposal function since it efficiently generates a new valid trajectory from a current one.

Although pivoting ensures solutions are positive, there may exist extreme points that don't fall on the grid of integer solutions and so do not satisfy the integer constraint. However, if we posit the existence of a \textit{null trajectory}, $0$, and associate all fractional solutions with the null trajectory, then simply ignore null samples, then we end up with samples from the posterior, as required (i.e. the Markov chain can pass through fractional states, but no sample is generated when doing so). However, we don't want to spend too much computational effort moving between fractional states, so we should ensure that the probability of being in a fractional state isn't much greater than that of being in an integer state. In order to encourage the Markov process away from these fractional states their probability is multiplied by a ``fractional penalty'' $e^{-kn}$ where $n$ is the number of non-integer values in the solution and $k$ is a constant parameter.

The use of pivoting is complicated somewhat when the solutions are degenerate. A degenerate solution is one that can be generated by more than one pivot state. This can occur when any of the basic variables are zero, since when we perform a pivot the value of a basic variable becomes constrained to zero; but if the basic-variable's value was zero to start with, constraining it to zero has no effect, so we can perform a pivot without changing the solution (for a theoretical development of degeneracy see \cite{zornig93degeneracy}). This is problematic because we need to assign a probability to each Markov state and if many pivot states correspond to the same solution, a pivot state can't be given the probability of its trajectory because this would result in degenerate states being ``counted'' multiple times. To maintain the correct distribution, the probabilities of all the degenerate pivot states of a given trajectory should sum to the probability of that trajectory.

To solve this problem in a computationally efficient way we introduce the concept of an \textit{ordered pivot state} which consists of a partition of the variables into basic and non-basic variables and an ordering of the zero-valued basic variables. Notice that since we represent $X_n$ as a vector in our standard form representation, we can represent an ordered pivot state We now associate a Markov state with each ordered pivot state, assigning it a probability according to algorithm \ref{probAlgorithm}:

\begin{algorithm}
\caption{Algorithm to calculate probability of a degeneracy state}
\label{probAlgorithm}
\begin{algorithmic}
\State $A \leftarrow$ an ordered tableau
\State $P_T \leftarrow$ the probability of the vertex that is the solution to this tableau
\State $P_d \leftarrow 1.0$
\State $\sigma \leftarrow$ the number of degenerate rows in $A$
\For{$i = 0 \dots \sigma-1$}
	\State $Cols \leftarrow$ the set of columns in A that have at least one non-zero value in rows $i \le r < \sigma$
	\State $P_d \leftarrow P_d/|Cols|$
\EndFor
\State \Return $P_d \times P_T$
\end{algorithmic}
\end{algorithm}

The transitions between states are the valid pivots and the swapping of position of any two degenerate rows. The proposal function is shown in algorithm \ref{proposal}

\begin{algorithm}
\caption{Proposal function}
\label{proposal}
\begin{algorithmic}
\Function{Proposal}{A}
\State $A' \leftarrow A$ (the ordered tableau of the current state)
\State $\alpha, \beta \leftarrow$ constant parameters
\State $p_0 \leftarrow$ the set of degenerate pivots of A (i.e. the ones that do not change the solution)
\State $p_1 \leftarrow$ the set of non-degenerate pivots of A (i.e. the ones that change the solution)
\If{\Call{Bernoulli}{$\alpha$}}
  \State $r \leftarrow$ choose member of $p_1$ with uniform probability
  \State perform pivot $r$ on $A'$
\ElsIf{\Call{Bernoulli}{$\beta$}}
  \State $r \leftarrow$ choose member of $p_0$ with uniform probability
  \State perform pivot $r$ on $A'$
\Else
  \State choose two degenerate rows $a$ and $b$ with uniform probability
  \State swap rows $a$ and $b$ of $A'$ 
\EndIf
\State \Return $A'$
\EndFunction
\end{algorithmic}
\end{algorithm}

We need to show that this assignment of probability to ordered tableaus has the property that the sum of the probabilities associated with a vertex is the probability of that vertex.

\begin{theorem}
If $\mathbb{E}(T)$ is the set of all ordered tableaus with solution $T$, and $P(A)$ is the probability assigned to ordered tableau $A$ by algorithm \ref{probAlgorithm} and $P_T$ is the probability assigned to vertex $T$ then
\[
\sum_{A \in \mathbb{E}(T)} P(A) = P_T
\]
\end{theorem}
\begin{proof}
Consider the stochastic algorithm \ref{unityProof}. It is clear that every possible output is an ordered tableau with solution $T$ and that every ordered tableau with solution $T$ is a possible output of the algorithm. The probability that algorithm \ref{unityProof} outputs tableau $A$ is
\[
\frac{1}{\prod_{i=0}^{\sigma-1} C_i^\sigma(A)} 
\]
where $C_i^\sigma(A)$ is the number of columns that have at least one non-zero value in rows $i \le r < \sigma$ in $A$ since $C_i^\sigma(A)$ is invariant under pivots on rows $i \le r < \sigma$. But this is exactly the probability $P_d$ in algorithm \ref{probAlgorithm}.

It is also clear that, with probability 1, the algorithm returns an ordered tableau, so the sum of the probabilities of all possible outputs of algorithm \ref{unityProof} must also be 1. So
\[
\sum_{A \in \mathbb{E}(T)} P_d(A) = 1
\]
but $P(A) = P_d(A)P_T$ so 
\[
\sum_{A \in \mathbb{E}(T)} P(A) = \sum_{A \in \mathbb{E}(T)} P_d(A)P_T = P_T
\]
\end{proof}

\begin{algorithm}
\caption{Random choice of ordered tableau with solution T}
\label{unityProof}
\begin{algorithmic}
\State $A \leftarrow $ any ordered tableau with solution $T$
\For{$i = 0 \dots \sigma-1$}
  \State $Cols \leftarrow$ the set of columns in A that have at least one non-zero value in rows $i \le r < \sigma$
  \State $r \leftarrow$ random member of $Cols$ chosen with uniform probability
  \State pivot on column $r$ and lowest index row, $i \le r < \sigma$, of $A$
  \State swap the newly pivoted row and the $i^{th}$ row of $A$
\EndFor
\State \Return A
\end{algorithmic}
\end{algorithm}

Given this, it's clear that all the necessary properties of the proposal function are fulfilled.

%\bibliographystyle{unsrtnat}
%\bibliographystyle{apalike} 
\bibliographystyle{apacite}
\bibliography{references}

\end{document}
