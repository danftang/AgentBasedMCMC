\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{amssymb,amsmath,amsthm}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{apacite}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\newtheorem{theorem}{Theorem}
\DeclareMathOperator\supp{supp}

\title{Sampling from the Bayesian poster of an agent-based model given partial observations}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

\author{
  Daniel Tang\\
  Leeds Institute for Data Analytics\thanks{This project has received funding from the European Research Council (ERC) under the European Unionâ€™s Horizon 2020 research and innovation programme (grant agreement No. 757455)}\\
  University of Leeds\\
  Leeds, UK\\
  \texttt{D.Tang@leeds.ac.uk} \\
  %% examples of more authors
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
}


\begin{document}
\maketitle

\begin{abstract}
abstract
\end{abstract}

% keywords can be removed
\keywords{Data assimilation, Bayesian inference, Agent based model, Integer linear programming, predator prey model}

\section{Introduction}
%##########################################


Suppose we have a timestepping ABM where agents have a finite number of possible internal states and a finite number of ways of acting on their world. Given this, we can define an ABM as:
\begin{itemize}
\item A domain of agent actions $\mathcal{A} =\{ a_0 ... a_n \}$

\item A domain of agent states $\mathcal{S} = \{\sigma_0 ... \sigma_m\}$

\item An agent timestep function, $a = \pi(\psi,\Psi)$, which is a computer program whose input is the agent's state $\psi \in \mathcal{S}$ and a (sparse) vector, $\Psi$, whose elements $\psi_i$ are the number of agents in state $\sigma_i$ in the model, and whose output is a chosen action $a \in \mathcal{A}$. The program may make calls to a random number generator, so the function is stochastic and we write $P(\pi(\psi,\Psi)=a)$ to be the probability that the program will return action $a$, given inputs $\psi$ and $\Psi$.

\item An agent transition tensor $F_\phi^{\psi a}$ whose elements give the number of agents in state $\phi$ that result from an agent in state $\psi$ performing act $a$ (including the acting agent).
\end{itemize}

Let a model timestep consist of a matrix $E$ whose elements $e_{\psi a}$ are the number of agents in state $\psi$ that perform act $a$ in this timestep. Similarly, let a model trajectory be a tensor $T^t_{\psi a}$ whose elements are the number of agents in state $\psi$ that perform act $a$ in timestep $t$.

A trajectory must satisfy a number of constraints in order to be a possible trajectory of an ABM. Since the elements of a trajectory are counts, they must all be non-negative integers. So we have the \textit{non-negative integer constraint} that
\begin{equation}
\forall t,\psi, a: T^t_{\psi a} \in \mathbb{Z}_{\ge 0}
\label{nonNegativeInt}
\end{equation}

A trajectory, $T^t_{\psi a}$, must also be \textit{continuous} which means that each agent that results from the actions of an agent in timestep $t$ must appear in the actions of timestep $t+1$. This can be expressed in terms of the \textit{continuity constraints}:
\begin{equation}
\forall t \in 1 ... n:\forall \phi: \sum_{\psi, a} F_\phi^{\psi a}T^{t-1}_{\psi a} - \sum_a T^t_{\phi a} = 0
\label{continuous}
\end{equation}

If a trajectory satisfies constraints \ref{nonNegativeInt} and \ref{continuous} we say that it is \textit{valid}.

Suppose we have a prior belief, $P_0(\Psi)$, over the state of the ABM at time $t=0$. The prior probability of a trajectory is then given by
\[
P(T^t_{\psi a}) =
\begin{cases}
P_0(\sum_aT^0_{\psi a}) \prod_{t, \psi, a} P(\pi(\psi,\sum_bT^{t}_{\phi b})=a)^{T^{t}_{\psi a}} & \text{if } T^t_{\psi a} \text{ is valid} \\
0 & \text{otherwise}\\
\end{cases}
\]

Suppose we also have a set of noisy, aggregate observations, $\Omega$ and an easily computed likelihood function $P(\Omega|T^t_{\psi a})$. Our aim is to generate a number of samples from the posterior distribution
\[
P(T^t_{\psi a}|\Omega) \propto P\left(\Omega \middle| T^{t}_{\psi a}\right)P(T^t_{\psi a})
\]

We assume that each observation is independent of the others given the trajectory, so that
\[
P(\Omega|T^t_{\psi a}) = \prod_{(\omega,v) \in \Omega} P(\omega=v|T^t_{\psi a})
\]

Also, for notational convenience, we express our prior belief in terms of a set of observations, $\Omega_0$, at $t=0$, so that $P_0(\sum_a T^0_{\psi a}) \propto \prod_{(\omega,v) \in \Omega_0} P(\omega=v|T^t_{\psi a})$ (the same can be done for any boundary conditions that aren't at $t=0$). The posterior can now be written as
\begin{equation}
P(T^t_{\psi a}|\Omega) \propto 
\begin{cases}
\prod_{(\omega,v) \in \Omega} P\left(\omega=v \middle| T^{t}_{\psi a}\right) \prod_{t, \psi, a}P(\pi(\psi,\sum_bT^{t}_{\phi b})=a)^{T^{t}_{\psi a}} & \text{if } T^t_{\psi a} \text{ is valid} \\
0 & \text{otherwise}\\
\end{cases}
\label{posterior}
\end{equation}

This posterior has zero probability for the vast majority of trajectories because most trajectories are invalid, contain an impossible action or are refuted by the observations. This makes sampling from this distribution vary difficult in practice. For example, even though we can generate samples from the prior by simply performing a forward execution of the model, it is often very unlikely that this sample will fit the observations, so techniques such as rejection sampling are not practical.

Our strategy in this paper will be to use Markov Chain Monte-Carlo sampling. However, this requires a proposal function which generates a new sample from the current one. This is often done by randomly perturbing the current sample. However, if we randomly perturb an ABM trajectory it's very unlikely that we'll end up with a trajectory that is valid, contains only possible actions and satisfies the observations. In practice, then, a random perturbation would almost always be rejected and we'd probably end up stuck on the initial sample until we grew old.

\section{Approximating the support of the posterior}
%##########################################


In order to solve this problem, we'll make the states of our Markov chain an approximation of the support of the posterior, $P(T^t_{\psi a}|\Omega)$, (i.e. the set of trajectories that have non-zero probability) and restrict our proposal function to perturbations that are in this approximation.

If we let
\[
P^t_{\pi \xi c}(T^s_{\psi a}) = P(\pi(\xi,\sum_bT^{t}_{\phi b})=c)^{T^{t}_{\psi a}}
\]
Then from equation \ref{posterior}
\begin{equation}
\supp (P( \,.\, |\Omega)) = \bigcap_{(\omega,v) \in \Omega}  \supp(P(\omega = v \mid . )) \cap \bigcap_{t, \xi, c} \supp(P^t_{\pi \xi c})
\label{support}
\end{equation}
i.e. in order for the posterior to be non-zero, all the observation likelihoods must be non-zero and the probability of each agent's action at every timestep must be non-zero.

In order to approximate this support, we first express each likelihood function $P(\omega=v|T^t_{\psi a})$ as a computer program $\omega(T^t_{\psi a})$ whose input is a trajectory and whose output is the value of the observation. This program may make calls to a random number generator, so the function is stochastic and we write $P(\omega(T^t_{\psi a}) = v)$ to denote the probability that $\omega(T^t_{\psi a})$ returns a value $v$. So equation \ref{support} now consists of the intersection of terms of the form $\supp(P(\rho(.) = y))$ where $\rho$ is a computer program whose input is a trajectory and y is a given output. So, we need a way to find, or approximate, the set of inputs of a computer program that would produce a given output, and to take the intersection of these sets. Our strategy here is to calculate a set of linear inequalities, $\mathcal{P}$, on trajectories that are satisfied for all $x$ such that $\rho(x)$ might return $y$. Note that the converse is not necessarily true; if $x$ satisfies $\mathcal{P}$ then it might not be possible for $\rho(x)$ to return $y$. So $\mathcal{P}$ can be thought of as an approximation of $\supp(P(\rho(.)=y))$ in that it may include some extra members. However, for our purposes, a certain amount of approximation is tolerable and won't result in any approximation in the Markov Chain. If we happen to choose a proposal from $\mathcal{P}$ that isn't in $\supp(P(\rho(.)=y))$ then it will just be rejected. This is fine as long as we generate acceptable proposals at a reasonable rate.

A computer program can be transformed into a set of linear inequalities using a technique known as \textit{abstract interpretation}\cite{cousot1977abstract}. Tools to do this already exist (e.g. PAGAI\cite{henry2012pagai}) and are used widely in applications such as the verification of safety critical systems\cite{blanchet2003static}. For our application we choose the abstract domain of convex polyhedra\cite{cousot1978automatic}\cite{becchi2018efficient}. Calls to a random number generator are dealt with, without loss of generality, by providing a single function \texttt{rand()} that returns a floating point number between 0 and 1 with uniform probability. In the abstract domain, this is equivalent to the generation of a new variable, $r$, that satisfies $0 \le r < 1$.

Once we have the linear approximations of the support of each program, the intersection of these supports is just the set of trajectories that satisfy all of the inequalities. So, if we let $\mathcal{P}(\rho(.)=v)$ be the set of inequalities which approximate $\supp(P(\rho(.)=v))$ then we have the \textit{support inequalities}
\begin{equation}
\supp(P(P(.|\Omega))) \subset \bigcap_{(\omega,v) \in \Omega}  \mathcal{P}(\omega(.) = v) \cap \bigcap_{t, \xi, c} \mathcal{P}(\pi'(\xi,t,.)=c)
\label{linearSupport}
\end{equation}
where
\[
\pi'(\xi, s, T^t_{\psi a}) = \pi(\xi,\sum_bT^{s}_{\phi b})
\]
In order to ensure the trajectory is valid, we also intersect with the constraints in \ref{continuous}, which are also linear. We can express the non-negative part of equation \ref{nonNegativeInt} as the linear constraints
\begin{equation}
\forall t, \psi, a: T^t_{\psi a} \ge 0.
\label{nonNegative}
\end{equation}

The integer part we will consider in the next section.

\section{From convex polyhedron to Markov process}
%#####################################################

Once we've generated a set of inequalities that contain the support of the posterior, we next need to form a Markov process whose states emit solutions to the inequalities and whose stationary distribution is the posterior $P(T \mid \Omega)$. I order to perform MCMC we'd like to define the Markov process in terms of a set of states, $\mathbb{S}$, and a stochastic proposal function $f:\mathbb{S} \to \mathbb{S}$ such that $P(f(s_n) = s_{n+1})$ defines the conditional transition probability $P(s_{n+1} \mid s_n)$. The proposal function should have the following properties:
\begin{itemize}
\item There should be a set of transitions with non-zero probability between any two states. This ensures proper mixing as time tends to infinity.

\item The probability of emitting a trajectory $T$ should be our target posterior probability $P(T \mid \Omega)$, and all emitted trajectories should be solutions of our set of linear equations.

\item For any transition from state $s_a \to s_b$ the probability of transitioning from $s_b \to s_a$ should be non-zero. This allows us to use the Metropolis Hastings algorithm to attain detailed balance.

\item The proposal function should be computationally efficient. 
\end{itemize}

\subsection{A proposal function for a Fermionic ABM}
%#############################################

We define a Fermionic ABM to be one where no two agents can share the same state at the same time. i.e. in addition to the validity constraints of equation \ref{nonNegativeInt} and \ref{continuous} the trajectory of a Fermionic ABM also satisfies the \textit{Fermionic constraint}
\begin{equation}
\forall t,\psi: \sum_a T^t_{\psi a} \le 1
\label{fermionic}
\end{equation}
in which case we call it a \textit{Fermionic trajectory}.

\begin{theorem}
All valid Fermionic trajectories are on the vertices of the convex polyhedron described by equations \ref{continuous}, \ref{nonNegative}, \ref{fermionic} and \ref{linearSupport}.
\end{theorem}
\begin{proof}
This can be seen immediately since equations \ref{nonNegative} and \ref{fermionic} describe a unit hupercube, so all integer solutions are on vertices.
\end{proof}

\begin{theorem}
For any pair of valid trajectories, $A$ and $B$, there exists a path along edges of the polyhedron from $A$ to $B$ that only traverses through integer solutions.
\end{theorem}
\begin{proof}

[Take the difference A-B and decompose into integer null vectors (loops)]

\end{proof}

Since all Fermionic trajectories are on vertices, the obvious way forward would be to define a Markov process whose states, $\mathbb{S}$, are the vertices of the polyhedron and whose transitions are its edges. So, the proposal function would choose from the neighbouring vertices of the current state. There may exist vertices that don't fall on the grid of integer solutions, so are not associated with valid trajectories. However, extra states can be added to a Markov process without affecting the emitted samples as long as the extra states do not emit samples (i.e. the process can pass through these states, but no sample is generated when doing so). However, we don't want to spend too much computational effort moving between non-emitting states, so we should ensure that the probability of being in a non-emitting state isn't much greater than that of being in an emitting state. In order to encourage the Markov process away from these fractional states their probability is multiplied by a ``fractional penalty'' $e^{-kn}$ where $n$ is the number of non-integer values in the solution and $k$ is a constant parameter.

This approach is computationally convenient as navigation along edges of a polyhedron can be achieved efficiently by using the pivoting operation of the Simplex algorithm\cite{dantzig1955generalized}\cite{thie2011introduction}. Given a system of $m$ linear equality constraints on $n$ variables (where any inequalities are turned into equalities by the addition of slack variables), let a \textit{pivot state} be a partition of the variables into $m$ \textit{basic variables} and $n-m$ \textit{non-basic variables} such that if we constrain all \textit{non-basic variables} to zero there remains a unique solution. Such solutions can be shown to be at a vertex of the polyhedron described by the constraints. A \textit{pivot} is a perturbation of a pivot state such that one of the basic variables is swapped with one of the non-basic variables so the set of basic variables loses one of its members and gains a new member from the set of non-basic variables, such that the perturbed state is also a valid pivot state. It can be shown that every edge of a convex polyhedron corresponds to a unique pivot, so moving along an edge can be achieved computationally by performing a pivot.

This use of pivoting is complicated somewhat when the vertices of the polyhedron are degenerate. A degenerate vertex is one that can be generated by more than one pivot state. This can occur when any of the basic variables are zero, since a pivot has the effect of making a basic variable non-basic, so its value will be constrained to zero; but if the basic-variable's value is zero to start with, constraining it to zero has no effect. If there are many zero-valued basic variables there may be a large number of pivots, and even sequences of pivots, that do not change the solution, and consequently many pivot states which have the same solution. This has the consequence that a degenerate vertex may have a very large number of neighbours, so choosing one at random becomes a non-trivial task since it would be computationally costly to simply enumerate them all and choose one\cite{gal1992new}\cite{yamada1994enumerating}.

An alternative strategy is to replace the Markov states representing degenerate vertices with multiple states. As long as they all emit the same trajectory and the sum of their probabilities is the probability of the vertex then the Markov process will still emit samples from the posterior.

Let an \textit{ordered tableau} be a simplex tableau where all degenerate rows (i.e. rows with value zero) are above all non-degenerate rows, and non-degenerate rows are ordered by the index of the variable that is pivoted-in on that row. We now associate a Markov state with each ordered tableau, assigning it a probability according to algorithm \ref{probAlgorithm}:

\begin{algorithm}
\caption{Algorithm to calculate probability of a degeneracy state}
\label{probAlgorithm}
\begin{algorithmic}
\State $A \leftarrow$ an ordered tableau
\State $P_T \leftarrow$ the probability of the vertex that is the solution to this tableau
\State $P_d \leftarrow 1.0$
\State $\sigma \leftarrow$ the number of degenerate rows in $A$
\For{$i = 0 \dots \sigma-1$}
	\State $Cols \leftarrow$ the set of columns in A that have at least one non-zero value in rows $i \le r < \sigma$
	\State $P_d \leftarrow P_d/|Cols|$
\EndFor
\State \Return $P_d \times P_T$
\end{algorithmic}
\end{algorithm}

The transitions between states are the valid pivots and the swapping of position of any two degenerate rows. The proposal function is shown in algorithm \ref{proposal}

\begin{algorithm}
\caption{Proposal function}
\label{proposal}
\begin{algorithmic}
\Function{Proposal}{A}
\State $A' \leftarrow A$ (the ordered tableau of the current state)
\State $\alpha, \beta \leftarrow$ constant parameters
\State $p_0 \leftarrow$ the set of degenerate pivots of A (i.e. the ones that do not change the solution)
\State $p_1 \leftarrow$ the set of non-degenerate pivots of A (i.e. the ones that change the solution)
\If{\Call{Bernoulli}{$\alpha$}}
  \State $r \leftarrow$ choose member of $p_1$ with uniform probability
  \State perform pivot $r$ on $A'$
\ElsIf{\Call{Bernoulli}{$\beta$}}
  \State $r \leftarrow$ choose member of $p_0$ with uniform probability
  \State perform pivot $r$ on $A'$
\Else
  \State choose two degenerate rows $a$ and $b$ with uniform probability
  \State swap rows $a$ and $b$ of $A'$ 
\EndIf
\State \Return $A'$
\EndFunction
\end{algorithmic}
\end{algorithm}

We need to show that this assignment of probability to ordered tableaus creates a Markov process that emits samples from the posterior. 

\begin{theorem}
The sum of the probabilities of all ordered tableaus of a vertex, $T$, is $P_T$ 
\end{theorem}
\begin{proof}

\end{proof}

We propose a computationally efficient solution based on the observation in \cite{yamada1994enumerating} that there is a one to one mapping between neighbours of a vertex and the extreme rays of
\begin{eqnarray*}
Ay & = & 0, \\
  y & \ge & 0
\end{eqnarray*}

where $A$ is the matrix formed from the rows of the simplex tableau that are equal to zero in the $b$ column. The extreme rays can be transformed to vertices by adding the constraint
\[
\sum_i y_i = 1
\]
 We'll call this the \textit{neighbourhood} polyhedron.

Note that if a vertex has $\sigma$ zero-valued basic variables (it is $\sigma$\textit{-degenerate}) then the neighbourhood polyhedron has $\sigma + 1$ constraints and $n-m+\sigma$ variables, so the number of neighbours is bounded above by
\[
\nu_{max} = \left. n-m+\sigma \choose \sigma + 1 \right.
\]
corresponding with the number of ways of choosing $\sigma + 1$ basic variables out of $n-m+\sigma$. With this in mind, we associate $\nu_{max}$ states with each vertex and split the probability equally between them, so that each state has a probability of
\[
P_s = \frac{P(T|\Omega)}{\left. n-m+\sigma \choose \sigma + 1 \right.}
\]
Each state is associated with a choice of $\sigma+1$ zero-valued variables. It could be that some of these aren't valid pivot states of the neighbourhood polynomial, but we map each Markov state to a unique vertex of the neighbourhood polynomial 

It helps to understand the structure of the pivot states associated with a degenerate vertex by thinking about the  ``degeneracy graph''\cite{zornig93degeneracy} of the vertex. This is the graph whose nodes are the pivot states and whose edges are the pivots between states.

Mapping each node on the degeneracy graph to a state in the Markov process has the disadvantage that we'd somehow have to assign probabilities to the nodes such that the sum of their probabilities is the probability of the vertex. However, calculating the number of nodes in a degeneracy graph is computationally expensive\cite{zornig93degeneracy} so it's not clear how we should assign probabilities to nodes.


In full generality, if there are $\sigma$ zero-valued basic variables, then the vertex can be associated with a \textit{degenerate pivot state} which is a partition of the variables $(D_1,D_0)$ such that $D_1$ is the set of non-zero valued basic-variables of size $|D_1| = m-\sigma$ and $D_0$ is the set of zero-valued variables (whether basic or non-basic) of size $|D| = n-m+\sigma$. We say that a pivot state \textit{matches} a vertex if its basic variables are a superset of $D_1$, and so has this vertex as its solution. 



 
 

Define a neighbour of a degenerate vertex as a vertex that can be reached by a single pivot (on a row with non-zero b) from one of the vertex's matched pivot states. i.e. Two vertices $A$ and $B$ are neighbours if there exists a pair of pivot states $a$ and $b$ such that $a$ matches $A$, $b$ matches $B$ and $a$ and $b$ are neighbours.

[minimise an augmented state over all variables?]

Pivoting-in a variable on a non-zero row makes that variable greater than zero, then $\sum_{j\in Q} x_j > 0$ must be true of all neighbours, where $Q$ is the set of non-basic columns with at least one positive coefficient on a non-zero row.

To turn this into a Markov process, begin with a polyhedron with $m$ constraints on $n$ variables. Consider now a vertex of that polyhedron with $\sigma$ zero-valued basic variables. Suppose out of those $\sigma$ basic variables, $m_1$ of them are on rows in the tableaux that have at least one positive coefficient (i.e. $A_1$ has $m_1$ rows)\footnote{[need to prove this is constant for all nodes in the degeneracy graph]}. Assign to that vertex a Markov state for each of the $n-m+\sigma \choose m_1$ sets of $m_1$ basic variables chosen from the $n-m+\sigma$ zero-valued variables; call this the \textit{neighbourhood state}. Note that it is clear that the neighbourhood polyhedron cannot have more vertices than there are neighbourhood states, but it may have fewer. Let $P(v)$ be the desired probability of the vertex and assign each Markov state a probability of
\[
P(s) = \frac{P(v)}{\left. n-m+\sigma \choose m_1 \right.}.
\]
This assures that the sum of the probabilities of all possible neighbourhood states assigned to a vertex is the desired probability of the vertex.

In order to generate proposal transitions for each state, first decide with fixed probability, $\alpha$, whether to make a transition to another state in the same vertex or a neighbouring vertex.

If we decide to transition to another state inside the same vertex then simply choose, with uniform probability, a member of the current neighbourhood state and swap it for a non-basic variable, again chosen uniformly. Since the proposed state has the same probability by definition, and the probability of making the reverse transition is the same as making the forward transition, then the proposal is always accepted.

If we choose to transition to a neighbouring vertex, first map the neighbourhood state, $\mu$, to a valid set of basic variables $B$ for the neighbourhood polyhedron using the following algorithm:

%\begin{algorithmic}
%\STATE $P \leftarrow$ simplex tableau for the neighbourhood polyhedron
%\STATE $Q \leftarrow \emptyset$
%\FOR{$i=0$ to $m$}
%\STATE $q \leftarrow m_i$
%\WHILE{the $q^{th}$ column of $P$ is zero on all rows $k \notin Q$}
%\STATE $q \leftarrow (q + 1) \mod (n-m+\sigma)$
%\ENDWHILE
%\STATE pivot $P$ on any non-zero row, $k \notin Q$, of the $q^{th}$ column
%\STATE add $q$ to $Q$
%\ENDFOR
%\end{algorithmic}

Note that this terminates as long as $A_1$ is of full rank, which is guaranteed as long as our original set of constraints has full rank.

[need to prove that this is a unique mapping for all start states]

Once we have a tableau of the neighbourhood polyhedron in it's mapped pivot state, there will be exactly one row which hasn't been pivoted by the above algorithm (since there will be $m_1+1$ constraints, the extra one being the $\sum_i y_i = 1$ constraint). Each possible pivot point on this row identifies a vertex of the neighbourhood polyhedron, which itself maps to a possible neighbour of the current vertex\footnote{We can prove that this row isn't equal to zero by disallowing the $\sum_i y_i = 1$ row  from being pivoted-in during the mapping from $\mu$ to $B$}. So, we take this set to be the set of possible destination vertices.


Given a destination vertex, we also need to choose a neighbourhood state at the destination. For this, we choose a state such that the current pivot state can be retained as much as possible, so as to reduce the computation needed to do the transition. To do this, we start with the current neighbourhood state and remove any variables that are non-zero in the destination. We then add/delete variables, chosen at random with a uniform probability, until we reach the correct number of members for the new value of $m_1$.

 So, if $r_x$ of the members of the source neighbourhood state are non-zero in the destination then and the source and destination states have $\sigma_x$ and $\sigma_y$ zero-valued basic variables respectively, and the size of the neighbourhood state in the source and destination is $m_{1x}$ and $m_{1y}$ respectively, then we need to choose $m_{1y} - m_{1x} +r_x$ new variables out of a total of $n-m+\sigma_y+m_{1x}-r_x$.
So, the acceptance probability is given by
\[
\alpha = \min\left(1,
\frac{P(Y) P_{Y \rightarrow X}\left.n-m+\sigma_x\choose m_{1x}\right. \left.n-m+\sigma_y + m_{1x} - r_x\choose m_{1y} - m_{1x} + r_x\right. }
{P(X) P_{X \rightarrow Y}\left.n-m+\sigma_y\choose m_{1y}\right. \left.n-m+\sigma_x + m_{1y} - r_y\choose m_{1x} - m_{1y} + r_y\right.}\right)
\]
So, in order to make this as close to 1 as possible, we choose a destination, from the set of possible pivots, with probability proportional to
\[
P_{X \rightarrow Y} \propto \frac{P(Y)\left.n-m+\sigma_y + m_{1x} - r_x\choose m_{1y} - m_{1x} + r_x\right.}{\left.n-m+\sigma_y\choose m_{1y}\right.}
\]


%#########################################################################################################
\section{Notes}

To prove that a vertex is a valid Fermionic trajecotry... 

We first show that if all variables $\tau^{t-1}_{\phi a}$, at time $t-1$, are non-negative integer on a vertex, then all variables $\tau^t_{\phi a}$, at time $t$, are also non-negative integer.

Since by conjecture all $\tau^{t-1}_{\phi a}$ are non-negative, integer and all $f^{\psi a}_\phi$ are, by definition, also non-negative integer, it follows that
\[
\sum_{\psi, a} f_\phi^{\psi a}\tau^{t-1}_{\psi a} \in \mathbb{Z}_{\ge 0}
\]
Substituting \ref{fermionic} into \ref{continuous} gives
\[
\sum_{\psi, a} f_\phi^{\psi a}\tau^{t-1}_{\psi a} \le 1
\]
so 
\[
\sum_{\psi, a} f_\phi^{\psi a}\tau^{t-1}_{\psi a} \in \left\{1,0\right\}
\]
substituting back into \ref{continuous} gives
\[
\sum_a \tau^t_{\phi a} \in \left\{0,1\right\}
\]

[starting with start state, this can take any binary value, now show that the first timestep is integer and induce for other timesteps. Perhaps add actions in groups that share the same start-state and show that vertices remain integer in the higher dimensional state. This can be shown more easily by introducing an auxiliary variable that is the number of agents in a given (phi,t) state]

[start with a fractional solution, recursively remove valid agent trajectories until there are non left, proving that it was a sum of valid trajectories][since all coefficients start at value 1, all ]

[show that a valid trajectory, once pivoted in, leaves all coefficients 1, so all neighbours of all valid trajectories are valid trajectories, so all vertices are valid. Since, before any pivots, each column has exactly one +ve value (i.e. the source of the action edge) and in a continuous trajectory there is exactly one action for each (state,time) pair and *the connectivity graph is a tree*]

[choose the smallest fractional value and subtract that weight of the integer solution that has maximum overlap]


[With just agent continuity constraints, we have a cone whose vertex is at zero and whose beams are the trajectories of single agents. Show that addition of integer upper bounds can only add corners at integer solutions, i.e. show that the intersection of the hypercube with the beams occurs at the vertices of the hypercube]

[]






\subsection{Agent policy constraints}

Let a policy be defined as a computer program whose input is $\psi$, the current state of the agent, and $\Psi$ a sparse vector consisting of the number of agents in other states, and whose return value, $\Phi$, is a vector consisting of the number of agents in each state resulting from the actions of this agent at the end of this timestep (including its own state, if applicable). The agent can die (set to dead state or don't include in return state), set its state or create another agent in a given state. There is also a Filp function which takes a probability and returns a Boolean whose probability of being true is the supplied probability.

The interface to $\Psi$ consists of $occupation(\phi)$ which returns the occupation number of state $\phi$. Occupation numbers can be added, subtracted, negated, multiplied by an integer and added to an integer to give another occupation number. There is a greater-than-or-equal-to operator that that compares with an integer to give a linear Boolean expression. Logical operations between linear Boolean expressions and local variables or expressions on $\psi$ will reduce to logical operations on true or false values.

The ``support semantics'' of the program gives the actions that are possible given a known $\psi$ but an unknown $\Psi$, where each path through the program is considered a separate action. The support semantics, for a given $\psi$, is a set of $(a,B,v)$ pairs where $a$ is a string of `0's and `1's denoting the direction of program flow at each branch, $B$ is a Boolean expression on linear inequalities on $\Psi$ for which $a$ is possible if $B$ is satisfied, and $v$ is an assignment of local variables to values (in the case of occupation number type variables, these will be linear expressions) which give the values of any variables that remain in scope after execution (possibly as a function of local variables in-scope at the start of execution).

Let $v(a)$ be the assignment to local variables at a given point in the program, given an execution along $a$. [Let $P(a,B)$ be the probability of following $a$ given that $B$ is satisfied.]

Let $S \otimes T$ be the set $\left\{(a+a',B\wedge B', v' \otimes v) : (a,B,v)\in S \wedge (a',B',v')\in T\wedge (B\wedge B' \ne false)\right\}$ where $a + a'$ is interpreted as concatenation and $(v'\otimes v)(x) = v'(v(x))$. 

The semantics of two consecutive statements with semantics $A$ and $B$ is $A\otimes B$.

A raw Boolean expression (i.e. as found in an if statement/loop guard) can be converted into a Boolean solely on $\Psi$, given values of any other local variables, by substituting the variables for their values. We write this, for convenience, as $C(v)$

 $b$, is a set of $(a,B)$ pairs representing the disjunction of its members. A linear Boolean expressions on $\Psi$ is just $\{(\emptyset,B)\}$ where $\emptyset$ is the empty string. b \texttt{ \&\& Flip(p)} means $\{(1+a,B) : (a,B)\in b \}$, \texttt{B || Flip(p)} means $\{(\emptyset,B),(1,true)\}$.

The negation of a raw Boolean, $b$, is $\{(\arg\min_{\{\overline{a}:(a,B)\in b\}}|a|,\bigwedge_{(a,B)\in b} \overline{B})\}$ if $\bigwedge_{(a,B)\in b} \overline{B} \ne false$ and all $\{a:(a,B)\in b\}$ agree (i.e. they are all prefixes of the longest member), or the empty set otherwise. The negation of a Flip string $\overline{a}$ is the string with all 

The semantics of an if statement on a raw Boolean expression, $B$, is $\{(1,B)\}\otimes D \cup \{(0,\overline{B})\}\otimes E $ where $B$ is the Boolean expression, $D$ is the semantics of the if body and $E$ is the semantics of the else body.
 
The semantics of a loops whose guard contains an expression on $\Psi$ is the fix-point of 
\[
S = S \otimes \left( \left\{(0,\overline{G})\right\} \cup  \{(1,G)\}\otimes D \right) 
\]
[The guard here may depend on program variables, so to get a fix-point they need to be part of the semantics. Better to just go around the loop collecting paths until the path becomes impossible]

[local variables may get entangled with $\Psi$ so need to be included in the semantics. e.g. if(Psi.occupation(1)) then x = 1 else x = 2. In which case, the semantics needs to be a function from paths to joint assignments to variables and Boolean expressions on Psi (and perhaps probabilities)]


%\bibliographystyle{unsrtnat}
%\bibliographystyle{apalike} 
\bibliographystyle{apacite}
\bibliography{references}

\end{document}
