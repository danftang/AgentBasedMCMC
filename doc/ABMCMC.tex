\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{amssymb,amsmath,amsthm}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{apacite}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\newtheorem{theorem}{Theorem}
\DeclareMathOperator\supp{supp}

\title{Sampling from the Bayesian poster of an agent-based model given partial observations}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

\author{
  Daniel Tang\\
  Leeds Institute for Data Analytics\thanks{This project has received funding from the European Research Council (ERC) under the European Unionâ€™s Horizon 2020 research and innovation programme (grant agreement No. 757455)}\\
  University of Leeds\\
  Leeds, UK\\
  \texttt{D.Tang@leeds.ac.uk} \\
  %% examples of more authors
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
}


\begin{document}
\maketitle

\begin{abstract}
abstract
\end{abstract}

% keywords can be removed
\keywords{Data assimilation, Bayesian inference, Agent based model, Integer linear programming, predator prey model}

\section{Introduction}
%##########################################


Suppose we have a timestepping ABM where agents have a finite number of possible internal states and a finite number of ways of acting on their world. Given this, we can define an ABM as:
\begin{itemize}
\item A domain of agent actions $\mathcal{A} =\{ a_0 ... a_n \}$

\item A domain of agent states $\mathcal{S} = \{\sigma_0 ... \sigma_m\}$

\item A computer program, $\pi(\psi,\Psi)$,  where $\psi \in \mathcal{S}$ is the agent's state and $\Psi$ is a (sparse) vector whose $i^{th}$ element is the number of agents in state $\sigma_i$ at the start of the timestep. The program can make calls to a random number generator, so its returned value may be non-deterministic and we write $P(\pi(\psi,\Psi)=a)$ to be the probability that the program will return value $a$, given inputs $\psi$ and $\Psi$. The program returns an action $a \in \mathcal{A}$ which is the action  performed by the agent in this timestep.

\item An agent transition tensor $F_\phi^{\psi a}$ whose elements give the number of agents in state $\phi$ that result from an agent in state $\psi$ performing act $a$ (including the acting agent).
\end{itemize}

Let a model timestep consist of a matrix $E$ whose elements $e_{\psi a}$ are the number of agents in state $\psi$ that perform act $a$ in this timestep. Similarly, let a model trajectory be a tensor $T^t_{\psi a}$ whose elements are the number of agents in state $\psi$ that perform act $a$ in timestep $t$.

A trajectory must satisfy a number of constraints in order to be a possible trajectory of an ABM. Since the elements of a trajectory are counts, they must all be non-negative integers, we'll call this the \textit{non-negative integer constraint}
\begin{equation}
\forall t,\psi, a: T^t_{\psi a} \in \mathbb{Z}_{\ge 0}
\label{nonNegativeInt}
\end{equation}

A trajectory, $T^t_{\psi a}$, must also be \textit{continuous} which means that each agent that results from the actions of an agent in timestep $t$ must appear in the actions of timestep $t+1$. This can be expressed in terms of the \textit{continuity constraints}:
\begin{equation}
\forall t \in 1 ... n:\forall \phi: \sum_{\psi, a} F_\phi^{\psi a}T^{t-1}_{\psi a} - \sum_a T^t_{\phi a} = 0
\label{continuous}
\end{equation}

If a trajectory satisfies constraints \ref{nonNegativeInt} and \ref{continuous} we say that it is \textit{valid}.

Suppose we have a prior belief, $P_0(\Psi)$, over the state of the ABM at time $t=0$. The prior probability of a trajectory is then given by
\[
P(T^t_{\psi a}) =
\begin{cases}
P_0(\sum_aT^0_{\psi a}) \prod_{t, \psi, a} P(\pi(\psi,\sum_bT^{t}_{\phi b})=a)^{T^{t}_{\psi a}} & \text{if } T^t_{\psi a} \text{ is valid} \\
0 & \text{otherwise}\\
\end{cases}
\]

Suppose we also have a set of noisy, aggregate observations, $\Omega$, with a likelihood function $P(\Omega|T^t_{\psi a})$. Our aim is to generate a number of samples from the posterior distribution
\[
P(T^t_{\psi a}|\Omega) \propto P\left(\Omega \middle| T^{t}_{\psi a}\right)P(T^t_{\psi a})
\]

We assume that observations are independent given the trajectory and that each individual observation in $\Omega$ can be simulated by a computer program $\omega(T^t_{\psi a})$ which may make calls to a random number generator. The probability, $P(\omega(T^t_{\psi a}) = v)$, that the program returns a value $v$ defines the likelihood of observing value $v$ upon making observation $\omega$ on trajectory $T^t_{\psi a}$. i.e. $\omega(T^t_{\psi a})$ is just a simulation of the observation, which is usually quite easy to write and to compute. 

Given this
\[
P(\Omega|T^t_{\psi a}) = \prod_{(\omega,v) \in \Omega} P(\omega(T^t_{\psi a})=v)
\]

Also, for notational convenience, we express our prior beliefs in terms of a set of observations, $\Omega_0$, at $t=0$, so that $P_0(\sum_a T^0_{\psi a}) \propto \prod_{(\omega,v) \in \Omega_0} P(\omega=v|T^t_{\psi a})$ (the same can be done for any priors that aren't at $t=0$). The posterior can now be written as
\begin{equation}
P(T^t_{\psi a}|\Omega) \propto 
\begin{cases}
\prod_{(\omega,v) \in \Omega} P\left(\omega(T^{t}_{\psi a})=v\right) \prod_{t, \psi, a}P(\pi(\psi,\sum_bT^{t}_{\phi b})=a)^{T^{t}_{\psi a}} & \text{if } T^t_{\psi a} \text{ is valid} \\
0 & \text{otherwise}\\
\end{cases}
\label{posterior}
\end{equation}
where $\Omega$ now includes any priors.

In many practical applications, sampling from this posterior is difficult because it has zero probability for the vast majority of trajectories (i.e. most trajectories are invalid, contain an impossible action or are refuted by the observations). For example, even though we can generate samples from the prior by simply performing a forward execution of the model, it is often very unlikely that this sample will fit the observations, so simple techniques such as rejection sampling are not practical.

Our strategy in this paper will be to use Markov Chain Monte-Carlo sampling. However, this method requires a proposal function which randomly generates the next sample given the current one. This suffers from the same problem that most trajectories have zero probability. For example if we generate a new sample by perturbing one or more elements of the last sample at random, it's very unlikely that we'll end up with a trajectory that is valid, contains only possible actions and satisfies the observations. So, the proposed next sample would almost certainly be rejected and we'd probably end up stuck on the first sample until we grew old.

\section{Approximating the support of the posterior}
%##########################################


In order to solve this problem, we'll make an approximation of the support of the posterior, $P(T^t_{\psi a}|\Omega)$, (i.e. the set of trajectories that have non-zero probability) and restrict our proposal function to perturbations that are in this approximation.

If we let
\[
\pi'(s, \xi, T^t_{\psi a}) = \pi(\xi,\sum_bT^{s}_{\phi b})
\]
Then from equation \ref{posterior}
\begin{equation}
\supp (P( \,.\, |\Omega)) = 
\bigcap_{(\omega,v) \in \Omega}  \supp\left(P\left(\omega(.)=v\right)\right) \cap
\bigcap_{t, \psi, a} \supp\left(P\left( \pi'(t,\psi,.) = a \right)\right) \cap
\left\{T^t_{\psi a} \mid T^t_{\psi a} \text{is valid}\right\}
\label{support}
\end{equation}
i.e. in order for the posterior to be non-zero, all the observation likelihoods must be non-zero and the probability of each agent's action at every timestep must be non-zero.

The first two terms in equation \ref{support} consists of the supports of various computer programs whose inputs are ABM trajectories and whose outputs are given. So, we need a way to find, or approximate, the set of trajectories that, when passed to a computer program, would produce a given output; then we need to take the intersection of these sets. Our strategy here is to calculate a set of linear inequalities, $\mathcal{P}$, on trajectories that are satisfied for all $x$ such that $P(\rho(x)=y) > 0$. Note that the converse is not necessarily true; if $x$ satisfies $\mathcal{P}$ then it might not be possible for $\rho(x)$ to return $y$. So $\mathcal{P}$ can be thought of as an approximation in that it is a superset of $\supp(P(\rho(.)=y))$ . However, for our purposes, this approximation won't result in any approximation in the Markov Chain. If we happen to choose a proposal from $\mathcal{P}$ that isn't in $\supp(P(\rho(.)=y))$ then it will just be rejected. This is fine as long as we generate acceptable proposals at a reasonable rate.

A computer program can be transformed into a set of linear inequalities using a technique known as \textit{abstract interpretation}\cite{cousot1977abstract}. Tools to do this already exist (e.g. PAGAI\cite{henry2012pagai}) and are used widely in applications such as the verification of safety critical systems\cite{blanchet2003static}. For our application we choose the abstract domain of convex polyhedra\cite{cousot1978automatic}\cite{becchi2018efficient}. Calls to a random number generator are dealt with, without loss of generality, by providing a single function \texttt{rand()} that returns a floating point number between 0 and 1 with uniform probability. In the abstract domain, this is equivalent to the generation of a new variable, $r$, that satisfies $0 \le r < 1$.

Once we have the linear approximations of the support of each program, the intersection of these supports is just the set of trajectories that satisfy all of the inequalities. So, if we let $\mathcal{P}(\rho(.)=v)$ be the set of inequalities which approximate $\supp(P(\rho(.)=v))$ then we have, from equation \ref{support}, the \textit{support inequalities}
\begin{equation}
\supp(P(P(.|\Omega))) \subset
\bigcap_{(\omega,v) \in \Omega}  \mathcal{P}(\omega(.) = v) \cap
\bigcap_{t, \psi, a} \mathcal{P}(\pi'(t,\psi,.)=a) \cap
\left\{T^t_{\psi a} \mid T^t_{\psi a} \text{is valid}\right\}
\label{linearSupport}
\end{equation}
In order to deal with the final term, which requires the trajectories in the support to be valid, we first intersect with the continuity constraints in \ref{continuous}, which are also linear. Finally we leave the non-negative integer constraints of equation \ref{nonNegativeInt} as separate constraints.

Without loss of generality, we express inequalities as equalities by introducing slack variables so that
\[
\sum_i c_i x_i \le y
\]
is equivalent to
\[
\begin{split}
 \sum_i c_i x_i + \lambda & = y \\
\text{subject to}\ \lambda & \ge 0 \\
\end{split}
\]
and
\[
\sum_i c_i x_i < y
\]
is equivalent to
\[
\begin{split}
 \sum_i c_i x_i + \lambda & = y \\
\text{subject to}\ \lambda & > 0 \\
\end{split}
\]

All the constraints can now be gathered into a single matrix equation
\[
\begin{split}
Ax &= y \\
\text{subject to}\ x_i &\ge 0,\  i \in X_{\ge}\\
x_j &> 0, \ j \in X_{>}\\
x_k &\in \mathbb{Z}, \ k \in X_{\ge} \cup X_{>}
\end{split}
\]
where the vector $x$ contains the elements of the trajectory tensor $T^t_{\psi a}$ and the slack variables $\lambda$.

\section{From convex polyhedron to Markov process}
%#####################################################

Once we've generated a set of inequalities that contain the support of the posterior, we next need to form a Markov process whose states emit solutions to the inequalities and whose stationary distribution is the posterior $P(T \mid \Omega)$. I order to perform MCMC we'd like to define the Markov process in terms of a set of states, $\mathbb{S}$, and a stochastic proposal function $f:\mathbb{S} \to \mathbb{S}$ such that $P(f(s_n) = s_{n+1})$ defines the conditional transition probability $P(s_{n+1} \mid s_n)$. The proposal function should have the following properties:
\begin{itemize}
\item There should be a set of transitions with non-zero probability between any two states. This ensures proper mixing as time tends to infinity.

\item The probability of emitting a trajectory $T$ should be our target posterior probability $P(T \mid \Omega)$, and all emitted trajectories should be solutions of our set of linear equations.

\item For any transition from state $s_a \to s_b$ the probability of transitioning from $s_b \to s_a$ should be non-zero. This allows us to use the Metropolis Hastings algorithm to attain detailed balance.

\item The proposal function should be computationally efficient. 
\end{itemize}

\subsection{A proposal function for a Fermionic ABM}
%#############################################

We define a Fermionic ABM to be one where no two agents can share the same state at the same time. i.e. in addition to the validity constraints of equation \ref{nonNegativeInt} and \ref{continuous} the trajectory of a Fermionic ABM also satisfies the \textit{Fermionic constraint}
\begin{equation}
\forall t,\psi: \sum_a T^t_{\psi a} \le 1
\label{fermionic}
\end{equation}
in which case we call it a \textit{Fermionic trajectory}.

\begin{theorem}
All valid Fermionic trajectories are on the vertices of the convex polyhedron described by equations \ref{continuous}, \ref{nonNegative}, \ref{fermionic} and \ref{linearSupport}.
\end{theorem}
\begin{proof}
This can be seen immediately since equations \ref{nonNegative} and \ref{fermionic} describe a unit hupercube, so all integer solutions are on vertices.
\end{proof}

\begin{theorem}
For any pair of valid trajectories, $A$ and $B$, there exists a path along edges of the polyhedron from $A$ to $B$ that only traverses through integer solutions.
\end{theorem}
\begin{proof}

[Take the difference A-B and decompose into integer null vectors (loops)]

\end{proof}

Since all Fermionic trajectories are on vertices, the obvious way forward would be to define a Markov process whose states, $\mathbb{S}$, are the vertices of the polyhedron and whose transitions are its edges. So, the proposal function would choose from the neighbouring vertices of the current state. There may exist vertices that don't fall on the grid of integer solutions, so are not associated with valid trajectories. However, extra states can be added to a Markov process without affecting the emitted samples as long as the extra states do not emit samples (i.e. the process can pass through these states, but no sample is generated when doing so). However, we don't want to spend too much computational effort moving between non-emitting states, so we should ensure that the probability of being in a non-emitting state isn't much greater than that of being in an emitting state. In order to encourage the Markov process away from these fractional states their probability is multiplied by a ``fractional penalty'' $e^{-kn}$ where $n$ is the number of non-integer values in the solution and $k$ is a constant parameter.

This approach is computationally convenient as navigation along edges of a polyhedron can be achieved efficiently by using the pivoting operation of the Simplex algorithm\cite{dantzig1955generalized}\cite{thie2011introduction}. Given a system of $m$ linear equality constraints on $n$ variables (where any inequalities are turned into equalities by the addition of slack variables), let a \textit{pivot state} be a partition of the variables into $m$ \textit{basic variables} and $n-m$ \textit{non-basic variables} such that if we constrain all \textit{non-basic variables} to zero there remains a unique solution. Such solutions can be shown to be at a vertex of the polyhedron described by the constraints. A \textit{pivot} is a perturbation of a pivot state such that one of the basic variables is swapped with one of the non-basic variables so the set of basic variables loses one of its members and gains a new member from the set of non-basic variables, such that the perturbed state is also a valid pivot state. It can be shown that every edge of a convex polyhedron corresponds to a unique pivot, so moving along an edge can be achieved computationally by performing a pivot.

This use of pivoting is complicated somewhat when the vertices of the polyhedron are degenerate. A degenerate vertex is one that can be generated by more than one pivot state. This can occur when any of the basic variables are zero, since a pivot has the effect of making a basic variable non-basic, so its value will be constrained to zero; but if the basic-variable's value is zero to start with, constraining it to zero has no effect. If there are many zero-valued basic variables there may be a large number of pivots, and even sequences of pivots, that do not change the solution, and consequently many pivot states which have the same solution. This has the consequence that a degenerate vertex may have a very large number of neighbours, so choosing one at random becomes a non-trivial task since it would be computationally costly to simply enumerate them all and choose one\cite{gal1992new}\cite{yamada1994enumerating}.

An alternative strategy is to replace the Markov states representing degenerate vertices with multiple states. As long as they all emit the same trajectory and the sum of their probabilities is the probability of the vertex then the Markov process will still emit samples from the posterior.

Let an \textit{ordered tableau} be a simplex tableau where all degenerate rows (i.e. rows with value zero) are above all non-degenerate rows, and non-degenerate rows are ordered by the index of the variable that is pivoted-in on that row. We now associate a Markov state with each ordered tableau, assigning it a probability according to algorithm \ref{probAlgorithm}:

\begin{algorithm}
\caption{Algorithm to calculate probability of a degeneracy state}
\label{probAlgorithm}
\begin{algorithmic}
\State $A \leftarrow$ an ordered tableau
\State $P_T \leftarrow$ the probability of the vertex that is the solution to this tableau
\State $P_d \leftarrow 1.0$
\State $\sigma \leftarrow$ the number of degenerate rows in $A$
\For{$i = 0 \dots \sigma-1$}
	\State $Cols \leftarrow$ the set of columns in A that have at least one non-zero value in rows $i \le r < \sigma$
	\State $P_d \leftarrow P_d/|Cols|$
\EndFor
\State \Return $P_d \times P_T$
\end{algorithmic}
\end{algorithm}

The transitions between states are the valid pivots and the swapping of position of any two degenerate rows. The proposal function is shown in algorithm \ref{proposal}

\begin{algorithm}
\caption{Proposal function}
\label{proposal}
\begin{algorithmic}
\Function{Proposal}{A}
\State $A' \leftarrow A$ (the ordered tableau of the current state)
\State $\alpha, \beta \leftarrow$ constant parameters
\State $p_0 \leftarrow$ the set of degenerate pivots of A (i.e. the ones that do not change the solution)
\State $p_1 \leftarrow$ the set of non-degenerate pivots of A (i.e. the ones that change the solution)
\If{\Call{Bernoulli}{$\alpha$}}
  \State $r \leftarrow$ choose member of $p_1$ with uniform probability
  \State perform pivot $r$ on $A'$
\ElsIf{\Call{Bernoulli}{$\beta$}}
  \State $r \leftarrow$ choose member of $p_0$ with uniform probability
  \State perform pivot $r$ on $A'$
\Else
  \State choose two degenerate rows $a$ and $b$ with uniform probability
  \State swap rows $a$ and $b$ of $A'$ 
\EndIf
\State \Return $A'$
\EndFunction
\end{algorithmic}
\end{algorithm}

We need to show that this assignment of probability to ordered tableaus has the property that the sum of the probabilities associated with a vertex is the probability of that vertex.

\begin{theorem}
If $\mathbb{E}(T)$ is the set of all ordered tableaus with solution $T$, and $P(A)$ is the probability assigned to ordered tableau $A$ by algorithm \ref{probAlgorithm} and $P_T$ is the probability assigned to vertex $T$ then
\[
\sum_{A \in \mathbb{E}(T)} P(A) = P_T
\]
\end{theorem}
\begin{proof}
Consider the stochastic algorithm \ref{unityProof}. It is clear that every possible output is an ordered tableau with solution $T$ and that every ordered tableau with solution $T$ is a possible output of the algorithm. The probability that algorithm \ref{unityProof} outputs tableau $A$ is
\[
\frac{1}{\prod_{i=0}^{\sigma-1} C_i^\sigma(A)} 
\]
where $C_i^\sigma(A)$ is the number of columns that have at least one non-zero value in rows $i \le r < \sigma$ in $A$ since $C_i^\sigma(A)$ is invariant under pivots on rows $i \le r < \sigma$. But this is exactly the probability $P_d$ in algorithm \ref{probAlgorithm}.

It is also clear that, with probability 1, the algorithm returns an ordered tableau, so the sum of the probabilities of all possible outputs of algorithm \ref{unityProof} must also be 1. So
\[
\sum_{A \in \mathbb{E}(T)} P_d(A) = 1
\]
but $P(A) = P_d(A)P_T$ so 
\[
\sum_{A \in \mathbb{E}(T)} P(A) = \sum_{A \in \mathbb{E}(T)} P_d(A)P_T = P_T
\]
\end{proof}

\begin{algorithm}
\caption{Random choice of ordered tableau with solution T}
\label{unityProof}
\begin{algorithmic}
\State $A \leftarrow $ any ordered tableau with solution $T$
\For{$i = 0 \dots \sigma-1$}
  \State $Cols \leftarrow$ the set of columns in A that have at least one non-zero value in rows $i \le r < \sigma$
  \State $r \leftarrow$ random member of $Cols$ chosen with uniform probability
  \State pivot on column $r$ and lowest index row, $i \le r < \sigma$, of $A$
  \State swap the newly pivoted row and the $i^{th}$ row of $A$
\EndFor
\State \Return A
\end{algorithmic}
\end{algorithm}

Given this, it's clear that all the necessary properties of the proposal function are fulfilled.

%\bibliographystyle{unsrtnat}
%\bibliographystyle{apalike} 
\bibliographystyle{apacite}
\bibliography{references}

\end{document}
